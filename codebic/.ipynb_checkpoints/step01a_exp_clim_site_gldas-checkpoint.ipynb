{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script will generate summary climate statistics for various sites from the GLDAS data.\n",
    "* Based on notes climate variables we decided on from here:\n",
    "    https://github.com/AileneKane/radcliffe/wiki/Team-background:-Notes-from-6-April-2016\n",
    " \n",
    "* Including:\n",
    "        mean temperature of the coldest month (C)\n",
    "        mean temperature of the warmest month (C)\n",
    "        number of chilling days (1 Sept - 31 Dec of previous year)\n",
    "        GDD above 5 from 1 Jan (calculate to 31 Dec, but pick a cutoff)\n",
    "        total amount of precipitation: April-Sept (mm)\n",
    "        total amount of precipitation: Oct-March (mm)\n",
    " \n",
    "* part of github project https://github.com/AileneKane/radcliffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reset the environment (start clean)\n",
    "%reset -f\n",
    "\n",
    "# Import Modules and define functions\n",
    "import calendar\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import netCDF4\n",
    "import matplotlib\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy\n",
    "import scipy.signal\n",
    "import scipy.io as sio\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "from IPython.display import display\n",
    "from mpl_toolkits.basemap import Basemap, cm, maskoceans\n",
    "import datetime as dt  # Python standard library datetime  module\n",
    "\n",
    "# Embeds plots inside the notebook (use in iPython Notebook)\n",
    "%matplotlib inline\n",
    "\n",
    "# Month Vector\n",
    "mons = np.arange(1,12+1)\n",
    "\n",
    "# GLDAS Data Directory\n",
    "dir_gldas  = '../Analyses/teambackground/output/SiteMet/'\n",
    "\n",
    "# Output Directory\n",
    "dir_output = '../Analyses/teambackground/output/ClimSum/'\n",
    "\n",
    "# List of GLDAS sites to calculate data from\n",
    "site_names = [ \\\n",
    "    'augspurger', \\\n",
    "    'bace', \\\n",
    "    'clarkduke', \\\n",
    "    'clarkharvard', \\\n",
    "    'cleland', \\\n",
    "    'concord', \\\n",
    "    'dunne', \\\n",
    "    'ellison', \\\n",
    "    'fargo', \\\n",
    "    'farnsworth', \\\n",
    "    'force', \\\n",
    "    'gothic', \\\n",
    "    'harvard', \\\n",
    "    'hubbard', \\\n",
    "    'konza', \\\n",
    "    'marchin', \\\n",
    "    'mikesell', \\\n",
    "    'mohonk', \\\n",
    "    'niwot', \\\n",
    "    'price', \\\n",
    "    'sherry', \\\n",
    "    'uwm', \\\n",
    "    'washdc']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through each site, loading the data and calculating the climate variables I want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augspurger\n",
      "bace\n",
      "clarkduke\n",
      "clarkharvard\n",
      "cleland\n",
      "concord\n",
      "dunne\n",
      "ellison\n",
      "fargo\n",
      "farnsworth\n",
      "force\n",
      "gothic\n",
      "harvard\n",
      "hubbard\n",
      "konza\n",
      "marchin\n",
      "mikesell\n",
      "mohonk\n",
      "niwot\n",
      "price\n",
      "sherry\n",
      "uwm\n",
      "washdc\n"
     ]
    }
   ],
   "source": [
    "# Header Text for Site Level Output\n",
    "header_txt = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug',\\\n",
    "             'Sep','Oct','Nov','Dec'] \n",
    "\n",
    "# Initialize Array to Store Site Summary Statistics\n",
    "col_names = ['TMEANcold','TMEANwarm','PRECamjjas','PRECondjfm',\\\n",
    "            'GDD0jfm','GDD0jfmam','GDD5jfm','GDD5jfmam','CHILLsond']\n",
    "climate_allsites = np.zeros((len(site_names),len(col_names)))*np.nan\n",
    "\n",
    "# Location of Different Month Periods over which I will be calculating statistics\n",
    "i_JFM    = np.where((mons>=1) & (mons<=3))\n",
    "i_OND    = np.where(mons>=10)\n",
    "i_JanMay = np.where((mons>=1) & (mons<=5))\n",
    "i_SepDec = np.where((mons>=9) & (mons<=12))\n",
    "i_AprSep = np.where((mons>=4) & (mons<=9))\n",
    "\n",
    "# Loop through each record across all sites\n",
    "for i_rec in enumerate(site_names):\n",
    "      \n",
    "    # Print current site\n",
    "    curr_site = site_names[i_rec[0]]\n",
    "    print(curr_site)\n",
    "        \n",
    "    # Open Climate Data for this site\n",
    "    df_currsite = pd.read_csv(dir_gldas+curr_site+'_gldas_2.0_1949-2010.csv')\n",
    "\n",
    "    # Pull out and create a vector of unique years\n",
    "    yrs_all  = np.array(df_currsite.year)\n",
    "    yrs_uniq = np.unique(yrs_all)\n",
    "    \n",
    "    # Initialize Matrices to store monthly data for current site\n",
    "    site_mon_tmean = np.zeros((yrs_uniq.size,mons.size))*np.nan\n",
    "    site_mon_prec  = np.zeros((yrs_uniq.size,mons.size))*np.nan\n",
    "    site_mon_gdd0  = np.zeros((yrs_uniq.size,mons.size))*np.nan\n",
    "    site_mon_gdd5  = np.zeros((yrs_uniq.size,mons.size))*np.nan\n",
    "    site_mon_chill = np.zeros((yrs_uniq.size,mons.size))*np.nan\n",
    "    \n",
    "    # FOR EACH YEAR, CALCULATE MONTHLY VALUES: averages, sums, etc.\n",
    "    # Loop through each year\n",
    "    for i_yr in enumerate(yrs_uniq):\n",
    "        \n",
    "        # Current year\n",
    "        curr_yr = i_yr[1]\n",
    "        \n",
    "        # Location of Current Year\n",
    "        loc_yr = df_currsite.year==curr_yr\n",
    "\n",
    "        # Pull out values for current year\n",
    "        month_curr = np.array(df_currsite.mo[loc_yr])\n",
    "        tmean_curr = np.array(df_currsite.tmean[loc_yr])-273.15\n",
    "        tmax_curr  = np.array(df_currsite.tmax[loc_yr])-273.15\n",
    "        tmin_curr  = np.array(df_currsite.tmin[loc_yr])-273.15\n",
    "        prec_curr  = np.array(df_currsite.precip[loc_yr])\n",
    "\n",
    "        # Loop through each month and make the calculations\n",
    "        for i_mon in enumerate(mons):\n",
    "                        \n",
    "            # Locations of days in current month\n",
    "            loc_mon = np.where(month_curr==i_mon[1])[0]\n",
    "\n",
    "            # Calculate Monthly Average Temperature\n",
    "            site_mon_tmean[i_yr[0],i_mon[0]] = np.mean(tmean_curr[loc_mon])\n",
    "            \n",
    "            # Calculate Monthly Precipitation\n",
    "            site_mon_prec[i_yr[0],i_mon[0]] = np.sum(prec_curr[loc_mon])\n",
    "            \n",
    "            # Calculate GDDs: Two Thresholds\n",
    "            gdd_poss                         = tmean_curr[loc_mon] # all days\n",
    "            site_mon_gdd0[i_yr[0],i_mon[0]]  = np.sum(gdd_poss[np.where(gdd_poss>=0)])\n",
    "            site_mon_gdd5[i_yr[0],i_mon[0]]  = np.sum(gdd_poss[np.where(gdd_poss>=5)]-5)\n",
    "            \n",
    "            # Calculate Chill Days\n",
    "            site_mon_chill[i_yr[0],i_mon[0]] = np.where(gdd_poss<5)[0].size\n",
    "    \n",
    "    # Dataframes for site level storage\n",
    "    df_out_tmean = pd.DataFrame(data=site_mon_tmean, index=yrs_uniq, columns=header_txt)\n",
    "    df_out_prec  = pd.DataFrame(data=site_mon_prec, index=yrs_uniq, columns=header_txt)\n",
    "    df_out_chill = pd.DataFrame(data=site_mon_chill, index=yrs_uniq, columns=header_txt)\n",
    "    df_out_gdd0  = pd.DataFrame(data=site_mon_gdd0, index=yrs_uniq, columns=header_txt)\n",
    "    df_out_gdd5  = pd.DataFrame(data=site_mon_gdd5, index=yrs_uniq, columns=header_txt)\n",
    "    \n",
    "    # Export Monthly Data as CSV\n",
    "    # Mean Monthly Temperature\n",
    "    outfile = dir_output+curr_site+'_mon_tmean.csv' # name of output file\n",
    "    df_out_tmean.to_csv(outfile,sep=',')            # save to file\n",
    "    # Monthly Precip\n",
    "    outfile = dir_output+curr_site+'_mon_prec.csv' # name of output file\n",
    "    df_out_prec.to_csv(outfile,sep=',')            # save to file\n",
    "    # Monthly Chill Days\n",
    "    outfile = dir_output+curr_site+'_mon_chill.csv' # name of output file\n",
    "    df_out_chill.to_csv(outfile,sep=',')            # save to file   \n",
    "    # Monthly GDD, base 0\n",
    "    outfile = dir_output+curr_site+'_mon_gdd0.csv' # name of output file\n",
    "    df_out_gdd0.to_csv(outfile,sep=',')            # save to file   \n",
    "    # Monthly GDD, base 5\n",
    "    outfile = dir_output+curr_site+'_mon_gdd5.csv' # name of output file\n",
    "    df_out_gdd5.to_csv(outfile,sep=',')            # save to file \n",
    "\n",
    "    # CROSS SITE SUMMARY STATISTICS\n",
    "    \n",
    "    # Calculate Monthly Mean Climatologies\n",
    "    mon_clim_tmean = np.mean(site_mon_tmean,axis=0)\n",
    "    mon_clim_prec  = np.mean(site_mon_prec,axis=0)   \n",
    "    mon_clim_prec  = np.mean(site_mon_prec,axis=0)   \n",
    "    mon_clim_gdd0  = np.mean(site_mon_gdd0,axis=0)   \n",
    "    mon_clim_gdd5  = np.mean(site_mon_gdd5,axis=0)   \n",
    "    mon_clim_chill = np.mean(site_mon_chill,axis=0)   \n",
    "\n",
    "    # Store this information\n",
    "    climate_allsites[i_rec[0],0] = np.min(mon_clim_tmean)                             # Mean Temp, Coldest Month\n",
    "    climate_allsites[i_rec[0],1] = np.max(mon_clim_tmean)                             # Mean Temp, Warmest Month\n",
    "    climate_allsites[i_rec[0],2] = np.sum(mon_clim_prec[i_AprSep])                    # Mean Prec, April-Sept\n",
    "    climate_allsites[i_rec[0],3] = np.sum(mon_clim_prec[i_JFM]+mon_clim_prec[i_OND])  # Mean Prec, Oct-March\n",
    "    climate_allsites[i_rec[0],4] = np.sum(mon_clim_gdd0[i_JFM])                       # GDD, base 0, Jan-Mar\n",
    "    climate_allsites[i_rec[0],5] = np.sum(mon_clim_gdd0[i_JanMay])                    # GDD, base 0, Jan-May\n",
    "    climate_allsites[i_rec[0],6] = np.sum(mon_clim_gdd5[i_JFM])                       # GDD, base 5, Jan-Mar\n",
    "    climate_allsites[i_rec[0],7] = np.sum(mon_clim_gdd5[i_JanMay])                    # GDD, base 5, Jan-May\n",
    "    climate_allsites[i_rec[0],8] = np.sum(mon_clim_chill[i_SepDec])                   # Chill days, Sep-Dec\n",
    "\n",
    "# Save Climate Summary Statistics\n",
    "outfile        = dir_output+'climate_site_summary.csv' # name of output file\n",
    "df_out_summary = pd.DataFrame(data=climate_allsites, index=site_names, columns=col_names)\n",
    "df_out_summary.to_csv(outfile,sep=',')            # save to file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
