{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script will generate climate statistics for individual SPECIES OBSERVATIONS from GLDAS for the EXPERIMENTAL SITES.\n",
    "* Based on notes climate variables we decided on from here:\n",
    "    https://github.com/AileneKane/radcliffe/wiki/Team-background:-Notes-from-6-April-2016\n",
    " \n",
    "* Including:\n",
    "        number of chilling days (1 Sept - 31 Dec of previous year)\n",
    "        GDD (0/5) from 1 Jan to start date\n",
    "        total amount of precipitation: January 1 to start date\n",
    " \n",
    "* part of github project https://github.com/AileneKane/radcliffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reset the environment (start clean)\n",
    "%reset -f\n",
    "\n",
    "# Import Modules and define functions\n",
    "import calendar\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import netCDF4\n",
    "import matplotlib\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy\n",
    "import scipy.signal\n",
    "import scipy.io as sio\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "from IPython.display import display\n",
    "from mpl_toolkits.basemap import Basemap, cm, maskoceans\n",
    "import datetime as dt  # Python standard library datetime  module\n",
    "\n",
    "# Embeds plots inside the notebook (use in iPython Notebook)\n",
    "%matplotlib inline\n",
    "\n",
    "# Month Vector\n",
    "mons = np.arange(1,12+1)\n",
    "\n",
    "# GLDAS Data Directory\n",
    "dir_gldas  = '../Analyses/teambackground/output/SiteMet/'\n",
    "\n",
    "# Output Directory\n",
    "dir_output = '../Analyses/teambackground/output/obsclim/'\n",
    "\n",
    "# List of GLDAS sites to calculate data from\n",
    "#   OBSERVATIONS ONLY\n",
    "site_names = [ \\\n",
    "    'concord', \\\n",
    "    'fargo', \\\n",
    "    'gothic', \\\n",
    "    'harvard', \\\n",
    "    'hubbard', \\\n",
    "    'konza', \\\n",
    "    'mikesell', \\\n",
    "    'mohonk', \\\n",
    "    'niwot', \\\n",
    "    'uwm', \\\n",
    "    'washdc']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load experimental phenological data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bolmgren', 'concord', 'fargo', 'fitter', 'gothic', 'harvard',\n",
       "       'hubbard', 'konza', 'marsham', 'mikesell', 'mohonk', 'niwot',\n",
       "       'rousi', 'uwm', 'washdc'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the csv file into a dataframe\n",
    "df_exppheno = pd.read_csv('../Analyses/obsphenoBIC.csv')\n",
    "\n",
    "# Pull out site codes, doy, year, phenophase event, genus, species\n",
    "exp_site    = df_exppheno.site\n",
    "exp_plot    = df_exppheno.plt\n",
    "exp_event   = df_exppheno.event\n",
    "exp_year    = df_exppheno.year\n",
    "exp_genus   = df_exppheno.genus\n",
    "exp_species = df_exppheno.species\n",
    "exp_doy     = df_exppheno.doy\n",
    "\n",
    "# Print out unique site names\n",
    "np.unique(exp_site)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through each site, and then calculate statistics for each individual record at that site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concord\n",
      "fargo\n",
      "gothic\n",
      "harvard\n",
      "hubbard\n",
      "konza\n",
      "mikesell\n",
      "mohonk\n",
      "niwot\n",
      "uwm\n",
      "washdc\n"
     ]
    }
   ],
   "source": [
    "# FROM GLDAS:\n",
    "# For the current site and each year, calculate daily GDD0, GDD5, and OND Chill Days\n",
    "for i_rec in enumerate(site_names):\n",
    "      \n",
    "    # Print current site\n",
    "    curr_site = site_names[i_rec[0]]\n",
    "    print(curr_site)\n",
    "    \n",
    "    # Find Location for current site\n",
    "    i_site = np.where(exp_site==curr_site)[0]\n",
    "    \n",
    "    # Pull out current site info\n",
    "    yrs_site     = np.float64(exp_year[i_site])\n",
    "    doy_site     = np.float64(exp_doy[i_site])\n",
    "   \n",
    "    # Open Climate Data for this site\n",
    "    df_currsite = pd.read_csv(dir_gldas+curr_site+'_gldas_2.0_1949-2010.csv')\n",
    "    \n",
    "    # Pull out and create a vector of unique years\n",
    "    yrs_all  = np.array(df_currsite.year)\n",
    "    yrs_uniq = np.unique(yrs_all)\n",
    "    \n",
    "    # FOR EACH YEAR OF GLDAS, CALCULATE DAILY GDD AND SEASONAL CHILL\n",
    "    gdd0_site     = np.zeros((yrs_uniq.size,365))\n",
    "    gdd5_site     = np.zeros((yrs_uniq.size,365))\n",
    "    chillOND_site = np.zeros((yrs_uniq.size))\n",
    "    \n",
    "    for i_yr in enumerate(yrs_uniq):\n",
    "        \n",
    "        # Current year\n",
    "        curr_yr = i_yr[1]\n",
    "        \n",
    "        # Location of Current Year\n",
    "        loc_yr = df_currsite.year==curr_yr\n",
    "    \n",
    "        # Month vector \n",
    "        month_vect = df_currsite.mo[loc_yr]\n",
    "    \n",
    "        # Pull out values for current year\n",
    "        tmean_curr = np.array(df_currsite.tmean[loc_yr])-273.15\n",
    "        \n",
    "        # Calculate GDD, base ZERO\n",
    "        gdd0                          = copy.deepcopy(tmean_curr)\n",
    "        gdd0[np.where(tmean_curr<=0)] = 0\n",
    "                \n",
    "        # Calculate GDD, base FIVE\n",
    "        gdd5                          = copy.deepcopy(tmean_curr)\n",
    "        gdd5[np.where(tmean_curr<5)]  = 0\n",
    "        gdd5[np.where(tmean_curr>=5)] = gdd5[np.where(tmean_curr>=5)]-5\n",
    "\n",
    "        # Calculate OND Chill Days\n",
    "        i_OND     = np.where(month_vect>=10)\n",
    "        tmean_OND = tmean_curr[i_OND]\n",
    "        chill_OND = np.where(tmean_OND<5)[0].size\n",
    "\n",
    "        # Store for analyses\n",
    "        gdd0_site[i_yr[0],0:365]     = gdd0[0:365]\n",
    "        gdd5_site[i_yr[0],0:365]     = gdd5[0:365]\n",
    "        chillOND_site[i_yr[0]]       = chill_OND\n",
    "\n",
    "    # NOW THAT GLDAS STATS HAVE BEEN CALCULATED\n",
    "    # Loop through each phenological observation, and calculate cumulative GDDs and chill days for that year+day\n",
    "\n",
    "    # Initialize Storage Arrays\n",
    "    pheno_site_gdd0     = np.zeros(yrs_site.size)\n",
    "    pheno_site_gdd5     = np.zeros(yrs_site.size)\n",
    "    pheno_site_chillOND = np.zeros(yrs_site.size)\n",
    "\n",
    "    # Loop through each phenological observation\n",
    "    for i_pheno in enumerate(yrs_site):\n",
    "        \n",
    "        # Find current year and date for phenological observation\n",
    "        pheno_yr  = np.int(yrs_site[i_pheno[0]])\n",
    "        pheno_doy = np.int(doy_site[i_pheno[0]])\n",
    "        \n",
    "        # Assign NaN value if no climate data available\n",
    "        # Other, make the GDD and Chill Day Calculation\n",
    "        if pheno_yr>2010:\n",
    "            pheno_site_gdd0[i_pheno[0]]     = np.nan\n",
    "            pheno_site_gdd5[i_pheno[0]]     = np.nan\n",
    "            pheno_site_chillOND[i_pheno[0]] = np.nan\n",
    "        elif pheno_yr<1949:\n",
    "            pheno_site_gdd0[i_pheno[0]]     = np.nan\n",
    "            pheno_site_gdd5[i_pheno[0]]     = np.nan\n",
    "            pheno_site_chillOND[i_pheno[0]] = np.nan\n",
    "        else:\n",
    "            # Index Locations\n",
    "            i_gdd_yr  = np.where(yrs_uniq==[pheno_yr])[0]\n",
    "            i_gdd_doy = np.arange(0,pheno_doy)\n",
    "        \n",
    "            # Store Data\n",
    "            pheno_site_gdd0[i_pheno[0]]     = np.sum(gdd0_site[i_gdd_yr,i_gdd_doy])\n",
    "            pheno_site_gdd5[i_pheno[0]]     = np.sum(gdd5_site[i_gdd_yr,i_gdd_doy])\n",
    "            pheno_site_chillOND[i_pheno[0]] = chillOND_site[i_gdd_yr-1]\n",
    "    \n",
    "    # CREATE DATAFRAME AND EXPORT\n",
    "    site_site    = exp_site[i_site]\n",
    "    genus_site   = exp_genus[i_site]\n",
    "    species_site = exp_species[i_site]\n",
    "    event_site   = exp_event[i_site]\n",
    "    plot_site    = exp_plot[i_site]\n",
    "\n",
    "    # Populate Dataframe\n",
    "    header_txt    = ['site','genus','species','event','year','doy','GDD0','GDD5','ChillDaysOND','plt']\n",
    "    df_out              = pd.DataFrame(columns=header_txt)\n",
    "    df_out.site         = site_site\n",
    "    df_out.genus        = genus_site\n",
    "    df_out.species      = species_site\n",
    "    df_out.event        = event_site\n",
    "    df_out.year         = yrs_site\n",
    "    df_out.doy          = doy_site\n",
    "    df_out.GDD0         = pheno_site_gdd0\n",
    "    df_out.GDD5         = pheno_site_gdd5\n",
    "    df_out.ChillDaysOND = pheno_site_chillOND\n",
    "    df_out.plt          = plot_site\n",
    "\n",
    "    # Save to File\n",
    "    outfile       = dir_output+curr_site+'_pheno_clim.csv' # name of output file\n",
    "    df_out.to_csv(outfile,sep=',')            # save to file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
